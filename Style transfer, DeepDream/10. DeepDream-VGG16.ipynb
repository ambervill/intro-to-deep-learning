{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация алгоритма обработки изображений DeepDream с помощью VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras import backend as K\n",
    "\n",
    "model = VGG16(weights='imagenet',\n",
    "              include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image_path = 'image.jpg'\n",
    "result_prefix = '1_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'features': {\n",
    "        'block2_conv2': 0.00004,\n",
    "        'block3_conv2': 0.00002,\n",
    "        'block4_conv3': 0.0005,\n",
    "        'block5_conv3': 0.001,\n",
    "    },\n",
    "}\n",
    "# Гиперпараметры для подбора эффектов\n",
    "step = 0.1  # Шаг градиентного восхождения\n",
    "num_octave = 3  # Количество октавных преобразований\n",
    "octave_scale = 2  # Коэффициент масштабирования октав\n",
    "iterations = 30  # Кол-во итераций на октаву\n",
    "max_loss = 100.  # Ограничение loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet',    include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Util function to open, resize and format pictures\n",
    "    # into appropriate tensors.\n",
    "    img = load_img(image_path)\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.2\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image shape (162, 200)\n",
      "..Loss value at 0 : 97.820786\n",
      "..Loss value at 1 : 100.78035\n",
      "..Loss value at 2 : 103.805595\n",
      "..Loss value at 3 : 106.91514\n",
      "..Loss value at 4 : 110.120445\n",
      "..Loss value at 5 : 113.42265\n",
      "..Loss value at 6 : 116.79276\n",
      "..Loss value at 7 : 120.23212\n",
      "..Loss value at 8 : 123.75211\n",
      "..Loss value at 9 : 127.404274\n",
      "..Loss value at 10 : 131.15454\n",
      "..Loss value at 11 : 134.95734\n",
      "..Loss value at 12 : 138.84492\n",
      "..Loss value at 13 : 142.82175\n",
      "..Loss value at 14 : 146.85234\n",
      "..Loss value at 15 : 150.96034\n",
      "..Loss value at 16 : 155.1086\n",
      "..Loss value at 17 : 159.36621\n",
      "..Loss value at 18 : 163.68747\n",
      "..Loss value at 19 : 168.0646\n",
      "..Loss value at 20 : 172.51965\n",
      "..Loss value at 21 : 177.06673\n",
      "..Loss value at 22 : 181.7297\n",
      "..Loss value at 23 : 186.46399\n",
      "..Loss value at 24 : 191.27129\n",
      "..Loss value at 25 : 196.15152\n",
      "..Loss value at 26 : 201.09499\n",
      "..Loss value at 27 : 206.09158\n",
      "..Loss value at 28 : 211.13937\n",
      "..Loss value at 29 : 216.23997\n",
      "Processing image shape (325, 400)\n",
      "..Loss value at 0 : 83.99853\n",
      "..Loss value at 1 : 87.56437\n",
      "..Loss value at 2 : 91.17495\n",
      "..Loss value at 3 : 94.85235\n",
      "..Loss value at 4 : 98.614784\n",
      "..Loss value at 5 : 102.45299\n",
      "..Loss value at 6 : 106.35726\n",
      "..Loss value at 7 : 110.32587\n",
      "..Loss value at 8 : 114.37063\n",
      "..Loss value at 9 : 118.47936\n",
      "..Loss value at 10 : 122.67421\n",
      "..Loss value at 11 : 126.95629\n",
      "..Loss value at 12 : 131.32571\n",
      "..Loss value at 13 : 135.76877\n",
      "..Loss value at 14 : 140.2837\n",
      "..Loss value at 15 : 144.88162\n",
      "..Loss value at 16 : 149.57916\n",
      "..Loss value at 17 : 154.36688\n",
      "..Loss value at 18 : 159.26024\n",
      "..Loss value at 19 : 164.255\n",
      "..Loss value at 20 : 169.32828\n",
      "..Loss value at 21 : 174.48799\n",
      "..Loss value at 22 : 179.74898\n",
      "..Loss value at 23 : 185.11069\n",
      "..Loss value at 24 : 190.56123\n",
      "..Loss value at 25 : 196.12236\n",
      "..Loss value at 26 : 201.80725\n",
      "..Loss value at 27 : 207.5979\n",
      "..Loss value at 28 : 213.5104\n",
      "..Loss value at 29 : 219.55899\n",
      "Processing image shape (650, 800)\n",
      "..Loss value at 0 : 70.89735\n",
      "..Loss value at 1 : 74.43502\n",
      "..Loss value at 2 : 78.02004\n",
      "..Loss value at 3 : 81.68417\n",
      "..Loss value at 4 : 85.43554\n",
      "..Loss value at 5 : 89.288086\n",
      "..Loss value at 6 : 93.26937\n",
      "..Loss value at 7 : 97.38502\n",
      "..Loss value at 8 : 101.658104\n",
      "..Loss value at 9 : 106.0968\n",
      "..Loss value at 10 : 110.70969\n",
      "..Loss value at 11 : 115.498276\n",
      "..Loss value at 12 : 120.44757\n",
      "..Loss value at 13 : 125.57265\n",
      "..Loss value at 14 : 130.89911\n",
      "..Loss value at 15 : 136.39697\n",
      "..Loss value at 16 : 142.1132\n",
      "..Loss value at 17 : 148.03696\n",
      "..Loss value at 18 : 154.15237\n",
      "..Loss value at 19 : 160.45767\n",
      "..Loss value at 20 : 166.97801\n",
      "..Loss value at 21 : 173.73386\n",
      "..Loss value at 22 : 180.67166\n",
      "..Loss value at 23 : 187.8261\n",
      "..Loss value at 24 : 195.22339\n",
      "..Loss value at 25 : 202.86931\n",
      "..Loss value at 26 : 210.81122\n",
      "..Loss value at 27 : 219.0027\n",
      "..Loss value at 28 : 227.51\n",
      "..Loss value at 29 : 236.36003\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(0)\n",
    "dream = model.input\n",
    "# Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "# Вводим целевую функцию\n",
    "loss = K.variable(0.)\n",
    "for layer_name in settings['features']:\n",
    "    if layer_name not in layer_dict:\n",
    "        raise ValueError('Layer ' + layer_name + ' not found in model.')\n",
    "    coeff = settings['features'][layer_name]\n",
    "    x = layer_dict[layer_name].output\n",
    "    # Для устранения краевых эффектов включаем только внутренние пикселы\n",
    "    scaling = K.prod(K.cast(K.shape(x), 'float32'))\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        # Целевая функция - L2-норма градиента\n",
    "        loss = loss + coeff * K.sum(K.square(x[:, :, 2: -2, 2: -2])) / scaling\n",
    "    else:\n",
    "        loss = loss + coeff * K.sum(K.square(x[:, 2: -2, 2: -2, :])) / scaling\n",
    "\n",
    "# Вычисляем градиенты loss по изображению\n",
    "grads = K.gradients(loss, dream)[0]\n",
    "# Нормализация градиента\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), K.epsilon())\n",
    "\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)\n",
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        factors = (1, 1,\n",
    "                   float(size[0]) / img.shape[2],\n",
    "                   float(size[1]) / img.shape[3])\n",
    "    else:\n",
    "        factors = (1,\n",
    "                   float(size[0]) / img.shape[1],\n",
    "                   float(size[1]) / img.shape[2],\n",
    "                   1)\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('..Loss value at', i, ':', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x\n",
    "\n",
    "img = preprocess_image(base_image_path)\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    original_shape = img.shape[2:]\n",
    "else:\n",
    "    original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('Processing image shape', shape)\n",
    "    img = resize_img(img, shape)\n",
    "    img = gradient_ascent(img,\n",
    "                          iterations=iterations,\n",
    "                          step=step,\n",
    "                          max_loss=max_loss)\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "    # Re-inject details\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "\n",
    "save_img(result_prefix + base_image_path, deprocess_image(np.copy(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
