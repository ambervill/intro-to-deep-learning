{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_elAxqq01SN"
   },
   "source": [
    "## Генератор человеко-читаемых дат на основе RNN и посимвольной генерации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0Nj4psY01SJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "from faker import Faker\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "Faker.seed(12345)\n",
    "random.seed(12345)\n",
    "\n",
    "# Define format of the data we would like to generate\n",
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'd MMM YYY', \n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY']\n",
    "\n",
    "# change this if you want it to work with another language\n",
    "LOCALES = ['en_US']\n",
    "\n",
    "def load_date():\n",
    "    \"\"\"\n",
    "        Loads some fake dates \n",
    "        :returns: tuple containing human readable string, machine readable string, and date object\n",
    "    \"\"\"\n",
    "    dt = fake.date_object()\n",
    "\n",
    "    try:\n",
    "        human_readable = format_date(dt, format=random.choice(FORMATS),  locale='en_US') # locale=random.choice(LOCALES))\n",
    "        human_readable = human_readable.lower()\n",
    "        human_readable = human_readable.replace(',','')\n",
    "        machine_readable = dt.isoformat()\n",
    "        \n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human_readable, machine_readable, dt\n",
    "\n",
    "def load_dataset(m):\n",
    "    \"\"\"\n",
    "        Loads a dataset with m examples and vocabularies\n",
    "        :m: the number of examples to generate\n",
    "    \"\"\"\n",
    "    \n",
    "    human_vocab = set()\n",
    "    machine_vocab = set()\n",
    "    dataset = []\n",
    "    Tx = 30\n",
    "    \n",
    "\n",
    "    for i in tqdm(range(m)):\n",
    "        h, m, _ = load_date()\n",
    "        if h is not None:\n",
    "            dataset.append((h, m))\n",
    "            human_vocab.update(tuple(h))\n",
    "            machine_vocab.update(tuple(m))\n",
    "    \n",
    "    human = dict(zip(sorted(human_vocab) + ['<unk>', '<pad>'], \n",
    "                     list(range(len(human_vocab) + 2))))\n",
    "    inv_machine = dict(enumerate(sorted(machine_vocab)))\n",
    "    machine = {v:k for k,v in inv_machine.items()}\n",
    " \n",
    "    return dataset, human, machine, inv_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:03<00:00, 29078.41it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 100000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1684573 total characters and 36 unique characters in your data.\n"
     ]
    }
   ],
   "source": [
    "# Формирование обучающей выборки\n",
    "d = np.array(dataset)\n",
    "data = '\\n'.join(d[:, 0])\n",
    "examples = d[:, 0]\n",
    "\n",
    "# Составление словаря токенов - a-z, \\n\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfmL668r01SQ"
   },
   "source": [
    "Выведем список всех используемых символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bh3QcYpr01SQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(chars)\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отображение символов на числовые индексы и обратно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YltsxeZ01SU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   0: '\\n',\n",
      "    1: ' ',\n",
      "    2: '.',\n",
      "    3: '/',\n",
      "    4: '0',\n",
      "    5: '1',\n",
      "    6: '2',\n",
      "    7: '3',\n",
      "    8: '4',\n",
      "    9: '5',\n",
      "    10: '6',\n",
      "    11: '7',\n",
      "    12: '8',\n",
      "    13: '9',\n",
      "    14: 'a',\n",
      "    15: 'b',\n",
      "    16: 'c',\n",
      "    17: 'd',\n",
      "    18: 'e',\n",
      "    19: 'f',\n",
      "    20: 'g',\n",
      "    21: 'h',\n",
      "    22: 'i',\n",
      "    23: 'j',\n",
      "    24: 'l',\n",
      "    25: 'm',\n",
      "    26: 'n',\n",
      "    27: 'o',\n",
      "    28: 'p',\n",
      "    29: 'r',\n",
      "    30: 's',\n",
      "    31: 't',\n",
      "    32: 'u',\n",
      "    33: 'v',\n",
      "    34: 'w',\n",
      "    35: 'y'}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(ix_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усечение (ограничение по модулю) градиентов во избежание \"градиентного взрыва\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yYvYeI501SX"
   },
   "outputs": [],
   "source": [
    "def clip(gradients, maxValue):\n",
    "    dWaa, dWax, dWya, db, dby = gradients['dWaa'], gradients['dWax'], gradients['dWya'], gradients['db'], gradients['dby']\n",
    "   \n",
    "    for gradient in [dWaa, dWax, dWya, db, dby]:\n",
    "        np.clip(gradient, -maxValue, maxValue, out=gradient)\n",
    "    \n",
    "    gradients = {\"dWaa\": dWaa, \"dWax\": dWax, \"dWya\": dWya, \"db\": db, \"dby\": dby}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация ячейки RNN и сэмплирование следующего символа в соответствии с распределением вероятностей, полученным на выходе RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIkYdtBx01Su"
   },
   "outputs": [],
   "source": [
    "def sample(parameters, char_to_ix, seed):\n",
    "    \"\"\"\n",
    "    parameters -- весовые матрицы и векторы смещения Waa, Wax, Wya, by, and b. \n",
    "    char_to_ix -- отображение символов на индексы.\n",
    "\n",
    "    Returns:\n",
    "    indices -- индексы сэмплированных символов.\n",
    "    \"\"\"\n",
    "    \n",
    "    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n",
    "    vocab_size = by.shape[0]\n",
    "    n_a = Waa.shape[1]\n",
    "    \n",
    "    # Значение первого входного вектора принимается нулевым\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    # Значение скрытого состояния в начале - нулевое\n",
    "    a_prev = np.zeros((n_a, 1))\n",
    "    \n",
    "    # Массив для хранения индексов сгенерированных символов\n",
    "    indices = []\n",
    "    \n",
    "    # Текущий индекс последнего сгенерированного символа\n",
    "    idx = -1 \n",
    "    \n",
    "    # Реализация работы RNN и сохранение результатов в массив indices \n",
    "    # Максимальная длина выходной последовательности - 50 символов \n",
    "    counter = 0\n",
    "    newline_character = char_to_ix['\\n']\n",
    "    \n",
    "    while idx != newline_character and counter != 50:\n",
    "        \n",
    "        # Уравнения прямого прохода\n",
    "        a = np.tanh(Waa @ a_prev + Wax @ x + b)\n",
    "        z = Wya @ a + by\n",
    "        y = softmax(z) \n",
    "        \n",
    "        # Сэмплирование из распределения вероятностей y\n",
    "        idx = np.random.choice(range(len(np.ravel(y))), p = np.ravel(y))\n",
    "\n",
    "        # Дописываем полученный индекс в indices\n",
    "        indices.append(idx)\n",
    "        \n",
    "        # Подготавливаем вход для следующего временного шага (равен выходу на текущем)\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[idx] = 1\n",
    "        \n",
    "        # Сохраняем скрытое состояние\n",
    "        a_prev = a\n",
    "        \n",
    "        counter +=1\n",
    "\n",
    "    if counter == 50:\n",
    "        indices.append(char_to_ix['\\n'])\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация одного цикла работы модели - прямой проход, вычисление градиента, обновление весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BbEdIgY01S3"
   },
   "outputs": [],
   "source": [
    "def optimize(X, Y, a_prev, parameters, learning_rate = 0.01):\n",
    "    \"\"\"\n",
    "    X -- элемент обучающей выборки.\n",
    "    Y = X, сдвинутый на 1 позицию влево\n",
    "    a_prev -- предыдущее скрытое состояние.\n",
    "    parameters:\n",
    "        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n",
    "        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "        b --  Bias, numpy array of shape (n_a, 1)\n",
    "        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "    learning_rate\n",
    "    \n",
    "    Returns:\n",
    "    loss -- функция потерь (кросс-энтропия)\n",
    "    gradients -- градиенты матриц и векторов смещения:\n",
    "        dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)\n",
    "        dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)\n",
    "        dWya -- Gradients of hidden-to-output weights, of shape (n_y, n_a)\n",
    "        db -- Gradients of bias vector, of shape (n_a, 1)\n",
    "        dby -- Gradients of output bias vector, of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Прямой проход\n",
    "    loss, cache = rnn_forward(X, Y, a_prev, parameters)\n",
    "    \n",
    "    # Обратный проход\n",
    "    gradients, a = rnn_backward(X, Y, parameters, cache)\n",
    "    \n",
    "    # Усечение градиентов\n",
    "    gradients = clip(gradients, 5)\n",
    "    \n",
    "    # Обновление параметров (градиентный шаг)\n",
    "    parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "    \n",
    "    \n",
    "    return loss, gradients, a[len(X)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели на обучающей выборке.\n",
    "Используется стохастический градиентный спуск, каждые 2000 итераций выводятся несколько примеров генерации названий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l214uNun01S_"
   },
   "outputs": [],
   "source": [
    "def model(ix_to_char, char_to_ix, num_iterations = 20000, n_a = 50, dino_names = 7, vocab_size = 36, verbose = False):\n",
    "    \"\"\"\n",
    "    Trains the model and generates dinosaur names. \n",
    "    \n",
    "    Arguments:\n",
    "    ix_to_char -- dictionary that maps the index to a character\n",
    "    char_to_ix -- dictionary that maps a character to an index\n",
    "    num_iterations -- number of iterations to train the model for\n",
    "    n_a -- number of units of the RNN cell\n",
    "    dino_names -- number of dinosaur names you want to sample at each iteration. \n",
    "    vocab_size -- number of unique characters found in the text (size of the vocabulary)\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- learned parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Инициализация параметров\n",
    "    n_x, n_y = vocab_size, vocab_size\n",
    "    parameters = initialize_parameters(n_a, n_x, n_y)\n",
    "    loss = get_initial_loss(vocab_size, dino_names)\n",
    "    \n",
    "    # Перемешивание обучающей выборки\n",
    "    np.random.shuffle(examples)\n",
    "    \n",
    "    # Инициализация начального состояния\n",
    "    a_prev = np.zeros((n_a, 1))\n",
    "    \n",
    "    # Главный цикл оптимизации\n",
    "    for j in range(num_iterations):\n",
    "        \n",
    "        # Выбираем элемент обучающей выборки\n",
    "        idx = j % len(examples)\n",
    "        \n",
    "        # Подаем его на вход, добавляем в начало токен None - сигнал начала генерации\n",
    "        single_example = examples[idx]\n",
    "        single_example_chars = [c for c in single_example]\n",
    "        single_example_ix = [char_to_ix[c] for c in single_example_chars]\n",
    "        X = [None] + single_example_ix\n",
    "        \n",
    "        # Подаем сдвинутую влево на 1 позицию последовательность на выход\n",
    "        ix_newline = char_to_ix['\\n']\n",
    "        Y = X[1:] + [ix_newline]\n",
    "\n",
    "        # Один шаг оптимизации\n",
    "        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate = 0.01)\n",
    "\n",
    "        # Выводим несколько примеров генерации названий по мере обучения\n",
    "        if j % 2000 == 0:\n",
    "            print('Iteration: %d' % j + '\\n')\n",
    "            for name in range(dino_names):\n",
    "                # Сэмплируем несколько выходов нейросети\n",
    "                sampled_indices = sample(parameters, char_to_ix, seed=42)\n",
    "                print_sample(sampled_indices, ix_to_char)\n",
    "      \n",
    "            print('\\n')\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-HvBlAnS01TB"
   },
   "source": [
    "Проверяем работу модели. По мере обучения качество генерации значительно улучшается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EH8Edc001TC",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "\n",
      "7000 t44rdei/1u.2pc1tyeu86m5b2ge0m3743m77t9u53l\n",
      "Pgu8ea8o a6fs7/wwva5ncif9.m6boy9bv\n",
      "I39wh\n",
      "N2jr vf\n",
      " 71ja v30li9yb4 4f7n7cu9gubm7.u3fej8pty10w6up\n",
      "Hh2y1rou5.b8h6/wucmmeel4mymlr8afi8a0\n",
      "P1i/gm/nv078.4lydyi3uy evw4/c19w1o/j./p3bwaufnp.p5\n",
      "\n",
      "\n",
      "Iteration: 2000\n",
      "\n",
      "Riday july 19 1982\n",
      "Sovtary optember 27 2919\n",
      "3 267 23 1976\n",
      "Sonday jhn3 24 2015\n",
      "1 2019\n",
      "V maril 2072\n",
      "Day jany 2 16 5atuul 2 2020\n",
      "\n",
      "\n",
      "Iteration: 4000\n",
      "\n",
      "11\n",
      "June 2020\n",
      "Sepr32922\n",
      "Ariepdec 2001\n",
      "T 20 1972\n",
      "Ter 1005\n",
      "T 21 2015\n",
      "\n",
      "\n",
      "Iteration: 6000\n",
      "\n",
      "Thur 7 2 1980\n",
      "T fet 1972\n",
      "Friday august 7 1981\n",
      "1 1979\n",
      "Mocd ber 2008\n",
      "Margh 24 20\n",
      "Marril 1012\n",
      "\n",
      "\n",
      "Iteration: 8000\n",
      "\n",
      "Augest 15 1979\n",
      "May 18 1991\n",
      "Wednesday run 1991\n",
      "6 1979\n",
      "September 1995\n",
      "Moce 1994\n",
      "September 1982\n",
      "\n",
      "\n",
      "Iteration: 10000\n",
      "\n",
      "19 05 1983\n",
      "Arcest 17 1998\n",
      "Sapr a 2012\n",
      "December 14 2006\n",
      "September 30 1989\n",
      "September 11 2002\n",
      "5 2019\n",
      "\n",
      "\n",
      "Iteration: 12000\n",
      "\n",
      "Ril 1978\n",
      "September 18 1972\n",
      "17 februly 1975\n",
      "November 1992\n",
      "Sepbember 4 1988\n",
      "3 sep 2009\n",
      "Sunday september 23 2013\n",
      "\n",
      "\n",
      "Iteration: 14000\n",
      "\n",
      "Decembey 12 1999\n",
      "Jan 3 2006\n",
      "5 2006\n",
      "February 25 1791\n",
      "7 1991\n",
      "September 12 1996\n",
      "Thurr 1 1998\n",
      "\n",
      "\n",
      "Iteration: 16000\n",
      "\n",
      "25 1973\n",
      "December 9 2011\n",
      "September 5 1983\n",
      "Sep 25 1995\n",
      "September 9 1971\n",
      "September 21 1970\n",
      "Sep 30 1999\n",
      "\n",
      "\n",
      "Iteration: 18000\n",
      "\n",
      "Moce 20 2012\n",
      "December 20 1999\n",
      "R 2001\n",
      "Jan 1975\n",
      "Uesturr 1073\n",
      "4 1991\n",
      "14 0974\n",
      "\n",
      "\n",
      "Iteration: 20000\n",
      "\n",
      "Jun 2002\n",
      "September 21 1993\n",
      "R 2009\n",
      "September 16 1971\n",
      "September 27 2018\n",
      "September 37 2008\n",
      "Thunsamber 30 1971\n",
      "\n",
      "\n",
      "Iteration: 22000\n",
      "\n",
      "December 21 1998\n",
      "Oce 21 1980\n",
      "Friday january 20 1992\n",
      "Saprie 28 1999\n",
      "1975\n",
      "Mary 26 1972\n",
      "R 1985\n",
      "\n",
      "\n",
      "Iteration: 24000\n",
      "\n",
      "4 2006\n",
      "Arg 21 1982\n",
      "Thursday april 1 1986\n",
      "Sapy apriday may 21 2011\n",
      "September 19 1983\n",
      "6 2007\n",
      "Tuesday april 20 1997\n",
      "\n",
      "\n",
      "Iteration: 26000\n",
      "\n",
      "September 30 1978\n",
      "17 1971\n",
      "16 2020\n",
      "September 28 1976\n",
      "September 29 1990\n",
      "2 1985\n",
      " 1976\n",
      "\n",
      "\n",
      "Iteration: 28000\n",
      "\n",
      "Ruary 17 1983\n",
      "Suer 29 1982\n",
      "Arg 24 1996\n",
      "Urc 14 5994\n",
      "Tuesday july 20 1978\n",
      "September 27 1976\n",
      "Oct 26 1983\n",
      "\n",
      "\n",
      "Iteration: 30000\n",
      "\n",
      "September 4 1979\n",
      "1apr 1974\n",
      "September 22 2006\n",
      "September 16 2014\n",
      "Tuesayr 13 1987\n",
      "Arch 10 2016\n",
      "4 1984\n",
      "\n",
      "\n",
      "Iteration: 32000\n",
      "\n",
      "Arig 20 1981\n",
      "Argust 4 2010\n",
      "Tepdey 20 1978\n",
      "September 29 2006\n",
      "Apr 30 1981\n",
      "Apr 24 1971\n",
      "September 12 1997\n",
      "\n",
      "\n",
      "Iteration: 34000\n",
      "\n",
      "September 9 1991\n",
      "September 29 2010\n",
      "Arcust 6 2010\n",
      "Maurc 1998\n",
      "R 2004\n",
      "9 2013\n",
      "Sepbember 2000\n",
      "\n",
      "\n",
      "Iteration: 36000\n",
      "\n",
      "8 13 5 1991\n",
      "19 2012\n",
      "September 15 1870\n",
      "9 20 1971\n",
      "22 1983\n",
      "Arg 20 1992\n",
      "July 1995\n",
      "\n",
      "\n",
      "Iteration: 38000\n",
      "\n",
      "September 3 1977\n",
      "Oce 11 2017\n",
      "March 14 1972\n",
      "September 15 1982\n",
      "11 1781\n",
      "September 25 1978\n",
      "March 17 2005\n",
      "\n",
      "\n",
      "Iteration: 40000\n",
      "\n",
      "Oce 15 1998\n",
      "Sapt ject 17 2003\n",
      "September 15 1986\n",
      "September 3 1983\n",
      "Arch 2 1998\n",
      "September 19 1981\n",
      "Marc 17 2001\n",
      "\n",
      "\n",
      "Iteration: 42000\n",
      "\n",
      "September 14 2016\n",
      "September 4 2018\n",
      "14 1989\n",
      " 198 2017\n",
      "September 3 2016\n",
      "September 20 1989\n",
      "September 31 1986\n",
      "\n",
      "\n",
      "Iteration: 44000\n",
      "\n",
      "Arcember 1 2000\n",
      "September 12 1985\n",
      "September 15 1992\n",
      "6 1971\n",
      "21 1970\n",
      "September 9 2014\n",
      "Arch 7 2000\n",
      "\n",
      "\n",
      "Iteration: 46000\n",
      "\n",
      "May 27 2004\n",
      "17 2002\n",
      "May 15 1984\n",
      "Nove 2019\n",
      "May 12 2020\n",
      "September 13 1983\n",
      "Friday march 3 1991\n",
      "\n",
      "\n",
      "Iteration: 48000\n",
      "\n",
      "Nov 2018\n",
      "September 24 1984\n",
      "September 14 1992\n",
      "Ausday july 6 1989\n",
      "September 15 2011\n",
      "September 20 2015\n",
      " 2012\n",
      "\n",
      "\n",
      "Iteration: 50000\n",
      "\n",
      "September 23 1970\n",
      "September 22 2010\n",
      "5 1982\n",
      "September 15 1988\n",
      "September 23 1995\n",
      "4 1981\n",
      "Jul 1995\n",
      "\n",
      "\n",
      "Iteration: 52000\n",
      "\n",
      "September 23 1991\n",
      "Novt 20 1976\n",
      "April 6 1990\n",
      "September 3 2071\n",
      "7 1196\n",
      "September 14 2001\n",
      "September 14 1980\n",
      "\n",
      "\n",
      "Iteration: 54000\n",
      "\n",
      "4 2011\n",
      "Arg 1042\n",
      "September 19 1977\n",
      "Mary 4 2018\n",
      "September 19 1988\n",
      "Arcday february 15 2017\n",
      "R 2119\n",
      "\n",
      "\n",
      "Iteration: 56000\n",
      "\n",
      "September 10 2011\n",
      "September 26 2012\n",
      "September 3 1996\n",
      " 2006\n",
      "Tember 20 2018\n",
      "18 9999\n",
      "September 5 1999\n",
      "\n",
      "\n",
      "Iteration: 58000\n",
      "\n",
      "Oct 18 1988\n",
      "March 27 1988\n",
      " 39 1994\n",
      "Friday august 3 1973\n",
      "September 38 1976\n",
      "September 13 1996\n",
      "April 11 2000\n",
      "\n",
      "\n",
      "Iteration: 60000\n",
      "\n",
      "Mary 16 2011\n",
      "Oct 13 2015\n",
      "Ari 12 1983\n",
      "Sapridary 5 1981\n",
      "September 22 1991\n",
      "September 28 1994\n",
      "September 10 2006\n",
      "\n",
      "\n",
      "Iteration: 62000\n",
      "\n",
      "September 7 1985\n",
      "Arcust 6 1983\n",
      "September 4 1989\n",
      "Arch 5 2006\n",
      "March 14 1997\n",
      "September 16 1994\n",
      "Arcust 12 1981\n",
      "\n",
      "\n",
      "Iteration: 64000\n",
      "\n",
      "R 1989\n",
      "September 13 2003\n",
      "September 23 1976\n",
      "Maer 24 2021\n",
      "Fri 5 1993\n",
      "September 13 2009\n",
      "Friday may 10 1980\n",
      "\n",
      "\n",
      "Iteration: 66000\n",
      "\n",
      "Fridayy 26 1992\n",
      "19 1997\n",
      "September 8 2007\n",
      "7 1941\n",
      "Tuesa3y 4 2017\n",
      "September 4 2018\n",
      "14 1993\n",
      "\n",
      "\n",
      "Iteration: 68000\n",
      "\n",
      "Mary 29 1995\n",
      "September 28 1970\n",
      "September 6 2017\n",
      "September 23 2000\n",
      "August 3 1985\n",
      "Octarcu 9 2018\n",
      "September 21 1983\n",
      "\n",
      "\n",
      "Iteration: 70000\n",
      "\n",
      "September 2 2019\n",
      "August 28 2004\n",
      "September 13 2017\n",
      "7 24 1993\n",
      "Maer 26 1973\n",
      "Friday may 21 1996\n",
      "September 15 2007\n",
      "\n",
      "\n",
      "Iteration: 72000\n",
      "\n",
      "September 6 2002\n",
      "September 28 1988\n",
      "September 18 2001\n",
      "September 18 2002\n",
      "May 4 1999\n",
      "28 2000\n",
      "Thusesdey 17 2002\n",
      "\n",
      "\n",
      "Iteration: 74000\n",
      "\n",
      "Julr 1996\n",
      "18 1995\n",
      "September 10 2012\n",
      "August 8 1991\n",
      "R 77 2021\n",
      "September 21 1990\n",
      "9 7 1988\n",
      "\n",
      "\n",
      "Iteration: 76000\n",
      "\n",
      "May 23 1978\n",
      "8 2007\n",
      "September 19 1972\n",
      "September 16 1986\n",
      "March 1 1988\n",
      "September 27 1988\n",
      "September 27 1973\n",
      "\n",
      "\n",
      "Iteration: 78000\n",
      "\n",
      "Day june 4 2005\n",
      "16 1972\n",
      "September 25 1994\n",
      "Ariary 14 2006\n",
      "Janr 9 1970\n",
      "September 2 1981\n",
      "August 14 1971\n",
      "\n",
      "\n",
      "Iteration: 80000\n",
      "\n",
      "September 1 1993\n",
      "Maer 8 1997\n",
      "28 2005\n",
      "September 2 1979\n",
      "Seprir 27 2020\n",
      "26 2008\n",
      "September 1 2006\n",
      "\n",
      "\n",
      "Iteration: 82000\n",
      "\n",
      "28 2118\n",
      "Maer 13 1984\n",
      "Ayusday september 22 1987\n",
      "September 11 1983\n",
      "Sep 18 1986\n",
      "September 27 1997\n",
      "Friday february 19 1997\n",
      "\n",
      "\n",
      "Iteration: 84000\n",
      "\n",
      "Becember 1 1971\n",
      "September 5 1978\n",
      "Seprir a9y 1976\n",
      "May 31 1995\n",
      "Oct 5 1982\n",
      "Tepr 18 1973\n",
      "November 1995\n",
      "\n",
      "\n",
      "Iteration: 86000\n",
      "\n",
      "Maurc 20 1975\n",
      "7 19 199atruary 27 2015\n",
      "Ruary 1974\n",
      "Ori 26 2007\n",
      "Aursday august 31 2013\n",
      "August 7 2007\n",
      "November 2005\n",
      "\n",
      "\n",
      "Iteration: 88000\n",
      "\n",
      "May 14 2003\n",
      "8 2020\n",
      "Sapr l 25 2013\n",
      "September 6 2014\n",
      "17 1992\n",
      "September 18 2002\n",
      "99 1993\n",
      "\n",
      "\n",
      "Iteration: 90000\n",
      "\n",
      "Thurr 11 1982\n",
      "March 7 1993\n",
      "September 22 1984\n",
      "3 1998\n",
      "Arguri 23 2007\n",
      "Oce 25 1976\n",
      "September 8 2018\n",
      "\n",
      "\n",
      "Iteration: 92000\n",
      "\n",
      "May 17 2011\n",
      "September 26 2012\n",
      "Aridnurrbry 1992\n",
      "Maer 13 1983\n",
      "September 7 1982\n",
      "3 2013\n",
      "Ruar 1988\n",
      "\n",
      "\n",
      "Iteration: 94000\n",
      "\n",
      "Oce 23 2004\n",
      "Sapy n 9 1979\n",
      "Fridary 30 1979\n",
      "January 1991\n",
      "Oce 9 1974\n",
      "September 5 2000\n",
      "September 7 1976\n",
      "\n",
      "\n",
      "Iteration: 96000\n",
      "\n",
      "September 24 1977\n",
      "Arc 13 1994\n",
      "September 4 2012\n",
      "9 2018\n",
      "September 13 1993\n",
      "Ber 21 2009\n",
      "November 1970\n",
      "\n",
      "\n",
      "Iteration: 98000\n",
      "\n",
      "September 7 2013\n",
      "Jul 0970\n",
      "September 8 1986\n",
      "Maer 2002\n",
      "September 5 1983\n",
      "O 198 1092\n",
      "Fri 25 1979\n",
      "\n",
      "\n",
      "Iteration: 100000\n",
      "\n",
      "September 11 1995\n",
      "5 1995\n",
      "8 1987\n",
      "September 29 1977\n",
      "August 5 2019\n",
      "Marc 14 1977\n",
      "September 13 2006\n",
      "\n",
      "\n",
      "Iteration: 102000\n",
      "\n",
      "8 2000\n",
      "4 1998\n",
      "Moer 29 1989\n",
      "Temnest 20 1992\n",
      "Nove 1973\n",
      " 19 2005\n",
      "Friday december 6 1991\n",
      "\n",
      "\n",
      "Iteration: 104000\n",
      "\n",
      "Arcest 28 2012\n",
      "Arcday november 30 1982\n",
      "Friday april 15 2002\n",
      "Augurr 2010\n",
      "September 9 2016\n",
      "Oce 90 2002\n",
      "September 20 1972\n",
      "\n",
      "\n",
      "Iteration: 106000\n",
      "\n",
      "Reh 2011\n",
      "September 20 1992\n",
      "Epderr 12 2000\n",
      "December 28 2011\n",
      "March 25 2010\n",
      "March 3 1981\n",
      "R 9 2010\n",
      "\n",
      "\n",
      "Iteration: 108000\n",
      "\n",
      "Marc 18 1981\n",
      "6 2015\n",
      "Oct 9 2010\n",
      "September 26 1974\n",
      "September 5 1982\n",
      "March 6 1998\n",
      "Oct 5 1983\n",
      "\n",
      "\n",
      "Iteration: 110000\n",
      "\n",
      "Oct 23 2015\n",
      "Moer 23 2017\n",
      "18 2014\n",
      "Arcepr 21 2020\n",
      "September 7 2006\n",
      "September 12 1974\n",
      "Maer 19 1979\n",
      "\n",
      "\n",
      "Iteration: 112000\n",
      "\n",
      "September 28 2005\n",
      "Sepcember 13 1982\n",
      "17 2018\n",
      "20 1979\n",
      "27 1999\n",
      "September 10 2018\n",
      "Ruary 2 2005\n",
      "\n",
      "\n",
      "Iteration: 114000\n",
      "\n",
      "5 20 1998\n",
      "11 1976\n",
      "3 2001\n",
      "Jauy 21 2003\n",
      "5 16 1992\n",
      "Ari 30 1997\n",
      "7 12 2003\n",
      "\n",
      "\n",
      "Iteration: 116000\n",
      "\n",
      "Ari 17 1989\n",
      "17 197710/24/82\n",
      "September 13 1988\n",
      "Ari 9 1984\n",
      "4 17 1993\n",
      "September 14 1974\n",
      "Ari 14 1970\n",
      "\n",
      "\n",
      "Iteration: 118000\n",
      "\n",
      "2 1988\n",
      "Teptember 13 2004\n",
      "7 8 2001\n",
      "Ari 18 1979\n",
      "7 19 1990\n",
      "Decday february 2 1984\n",
      "9 7 1998\n",
      "\n",
      "\n",
      "Iteration: 120000\n",
      "\n",
      "Ruary 22 2009\n",
      "September 9 2007\n",
      "Ari 23 1974\n",
      "Arce 5 2002\n",
      "September 30 2017\n",
      "September 27 1973\n",
      "September 29 1973\n",
      "\n",
      "\n",
      "Iteration: 122000\n",
      "\n",
      "May 18 1975\n",
      "Ari 28 1974\n",
      "Ariday april 2 1985\n",
      "May 21 1976\n",
      "Augu 7 2019\n",
      "July 25 1978\n",
      "September 25 1998\n",
      "\n",
      "\n",
      "Iteration: 124000\n",
      "\n",
      "September 8 1974\n",
      "6 9 2015\n",
      "Maer 27 2003\n",
      "August 10 2017\n",
      "September 15 1982\n",
      "Sapridary 9 1970\n",
      "9 8 2002\n",
      "\n",
      "\n",
      "Iteration: 126000\n",
      "\n",
      "20 1980\n",
      "30 2020\n",
      "September 12 1973\n",
      "Ariu 2 1974\n",
      "8 2005\n",
      "Auru 21 1970\n",
      "Tuary 19 1982\n",
      "\n",
      "\n",
      "Iteration: 128000\n",
      "\n",
      "Seprember 27 1993\n",
      "Maer 18 2017\n",
      "Augu 4 1985\n",
      "4/80\n",
      "28 1990\n",
      "7 21 1973\n",
      "Maer 1 1976\n",
      "\n",
      "\n",
      "Iteration: 130000\n",
      "\n",
      "September 30 1979\n",
      "September 27 1988\n",
      "Oce 10 2002\n",
      "Augurt 27 2015\n",
      "Decday august 27 1983\n",
      "28 1975\n",
      "September 13 1971\n",
      "\n",
      "\n",
      "Iteration: 132000\n",
      "\n",
      "Oveobry 14 1983\n",
      "Oce 29 1987\n",
      "Maer 22 1985\n",
      "Arcu 18 1989\n",
      "Oce 18 1985\n",
      "Maer 26 2012\n",
      "Aril 5 1988\n",
      "\n",
      "\n",
      "Iteration: 134000\n",
      "\n",
      "Ariday april 21 1972\n",
      "9 3012\n",
      "Rce 6 2000\n",
      "September 18 2003\n",
      "Oce 17 2016\n",
      "July 29 1991\n",
      "Augu 3 2001\n",
      "\n",
      "\n",
      "Iteration: 136000\n",
      "\n",
      "14 9994\n",
      "3 2002\n",
      "September 12 1991\n",
      "Apr 1 2018\n",
      "Ari 18 1989\n",
      "May 10 2001\n",
      "May 1 2020\n",
      "\n",
      "\n",
      "Iteration: 138000\n",
      "\n",
      " 1974\n",
      "September 16 1974\n",
      "Friday september 12 1991\n",
      "September 30 2006\n",
      "May 15 1980\n",
      "September 11 2015\n",
      "20 12\n",
      "\n",
      "\n",
      "Iteration: 140000\n",
      "\n",
      "September 31 1994\n",
      "Orir 14 1982\n",
      "Maer 8 2017\n",
      "September 12 2000\n",
      "Sapril 17 1993\n",
      "Arch 8 1970\n",
      "7 8994\n",
      "\n",
      "\n",
      "Iteration: 142000\n",
      "\n",
      "July 14 1980\n",
      "September 2 1976\n",
      "Friday april 23 2001\n",
      "September 2 1976\n",
      "18 0978\n",
      "Novt7brarr 26 1979\n",
      "Maury 3 2006\n",
      "\n",
      "\n",
      "Iteration: 144000\n",
      "\n",
      "Ruary 9 2003\n",
      "Ari 10 2006\n",
      "Novt 1 1991\n",
      "20 0990\n",
      "Oriday october 31 1982\n",
      "Ary 28 2000\n",
      "3 1975\n",
      "\n",
      "\n",
      "Iteration: 146000\n",
      "\n",
      "Mber 10 2020\n",
      "September 22 2013\n",
      "September 23 1994\n",
      "Maer 21 1986\n",
      "September 12 1977\n",
      "Maer 17 2001\n",
      "December 26 1992\n",
      "\n",
      "\n",
      "Iteration: 148000\n",
      "\n",
      "Auesday september 28 1982\n",
      "September 5 2008\n",
      "Ariday june 19 1999\n",
      "September 6 1992\n",
      "September 17 2011\n",
      "Ariday october 6 2011\n",
      "September 7 1988\n",
      "\n",
      "\n",
      "Iteration: 150000\n",
      "\n",
      "Marr m 2015\n",
      "May 17 1982\n",
      "Rune 28 1993\n",
      "September 29 2019\n",
      "June 20 1997\n",
      "Ariday march 28 1998\n",
      "November 6 2006\n",
      "\n",
      "\n",
      "Iteration: 152000\n",
      "\n",
      "September 13 1994\n",
      "Seprember 12 1994\n",
      "Ari 2 1970\n",
      " 19 1996\n",
      "17 1970\n",
      "December 21 2014\n",
      "Tuesday november 22 2005\n",
      "\n",
      "\n",
      "Iteration: 154000\n",
      "\n",
      "8 2016\n",
      "Moer 18 2012\n",
      "Ruary 19 2002\n",
      "Maer 19 2005\n",
      "Thurrday june 28 1984\n",
      "Maer 11 2011\n",
      "May 30 1991\n",
      "\n",
      "\n",
      "Iteration: 156000\n",
      "\n",
      "Augu 9 2012\n",
      "Maer 17 1994\n",
      "May 27 1981\n",
      "September 22 2002\n",
      "Maer 1 2013\n",
      "Maer 25 1977\n",
      "September 24 1996\n",
      "\n",
      "\n",
      "Iteration: 158000\n",
      "\n",
      "Ari 4 1976\n",
      "3 8993\n",
      "M7est 7 2019\n",
      "Oce b 1975\n",
      "September 9 1973\n",
      "September 33 1974\n",
      "September 14 2009\n",
      "\n",
      "\n",
      "Iteration: 160000\n",
      "\n",
      "September 5 2008\n",
      "Ariu 1 2015\n",
      "Augdrch 1 2009\n",
      "September 20 2011\n",
      "Marr 12 2004\n",
      "Sapridecr 8 1973\n",
      "7 7 1998\n",
      "\n",
      "\n",
      "Iteration: 162000\n",
      "\n",
      "May 1 2004\n",
      "Oril 16 1992\n",
      "20 1987\n",
      "May 23 2014\n",
      "November 17 2009\n",
      "Maer 19 2019\n",
      "Arcu 16 2021\n",
      "\n",
      "\n",
      "Iteration: 164000\n",
      "\n",
      "Ary 1 1976\n",
      "Ariday april 6 1989\n",
      "19 17\n",
      "June 10 2020\n",
      "May 6 2019\n",
      "Rin 26 1999\n",
      "May 5 1990\n",
      "\n",
      "\n",
      "Iteration: 166000\n",
      "\n",
      "Apr 11 2017\n",
      "Oct 17 1987\n",
      "Maer 23 1994\n",
      "Sunday february 8 1987\n",
      "6 2017\n",
      "September 25 1996\n",
      "17 2005\n",
      "\n",
      "\n",
      "Iteration: 168000\n",
      "\n",
      "Maer 22 2010\n",
      "8 2001\n",
      "Sunday may 19 2009\n",
      "Decr 19 2001\n",
      "7 1978\n",
      "Friday july 15 2000\n",
      "Sunday february 8 1981\n",
      "\n",
      "\n",
      "Iteration: 170000\n",
      "\n",
      "Apr 24 2004\n",
      "May 5 2009\n",
      "September 3 2007\n",
      "Sapridoce 14 1996\n",
      "7 2016\n",
      "Maer 23 2003\n",
      "12 1981\n",
      "\n",
      "\n",
      "Iteration: 172000\n",
      "\n",
      "Maer 1 1999\n",
      "Oce ber 2005\n",
      "September 13 2002\n",
      "Saursday may 28 2000\n",
      "5 1974\n",
      "7 1998\n",
      "Sapr 4 0988\n",
      "\n",
      "\n",
      "Iteration: 174000\n",
      "\n",
      "Seprember 15 1994\n",
      "Mayri 16 1995\n",
      "September 6 1983\n",
      " 2019\n",
      "Ruer 10 1985\n",
      "27 2017\n",
      "3 1989\n",
      "\n",
      "\n",
      "Iteration: 176000\n",
      "\n",
      "January 28 2013\n",
      "Marrh 24 1976\n",
      "September 20 1972\n",
      "Sapridayy 6 1983\n",
      "Augurc 4 2003\n",
      "Ariu 17 1995\n",
      "September 6 1985\n",
      "\n",
      "\n",
      "Iteration: 178000\n",
      "\n",
      "September 6 2019\n",
      "Rh 15 2007\n",
      "Sapurcu 1 2011\n",
      "9h 9991\n",
      "98 20211 december 1980\n",
      "Sapriary 7 2015\n",
      "September 16 1992\n",
      "\n",
      "\n",
      "Iteration: 180000\n",
      "\n",
      "Arie 9 2016\n",
      "September 14 2012\n",
      "September 4 2019\n",
      "Ovember 16 2011\n",
      "78 20\n",
      "Ariueb 28 1999\n",
      "Nuee 2012021.07.93\n",
      "\n",
      "\n",
      "Iteration: 182000\n",
      "\n",
      "Aurch 8 2013\n",
      "September 22 1993\n",
      "August 26 1973\n",
      "March 26 2013\n",
      "Sunday december 7 2006\n",
      "March 4 1994\n",
      "July 10 1995\n",
      "\n",
      "\n",
      "Iteration: 184000\n",
      "\n",
      "September 9 1988\n",
      "March 23 1995\n",
      "Rce b 1978\n",
      "September 16 2013\n",
      "Saturday november 1 1992\n",
      "August 29 1989\n",
      "18 1986\n",
      "\n",
      "\n",
      "Iteration: 186000\n",
      "\n",
      "Day march 8 2009\n",
      "Oce 22 1992\n",
      "Ruary 18 1971\n",
      "Sapridecr 23 1983\n",
      "Sapridecr 12 1987\n",
      "Ocember 13 1983\n",
      "Sunt 11 2019\n",
      "\n",
      "\n",
      "Iteration: 188000\n",
      "\n",
      "Maer 1 1970\n",
      "Suer 3 1982\n",
      "Oct 10 1990\n",
      "Saturday september 5 2020\n",
      "Oct 18 1582\n",
      "May 13 1980\n",
      "Ari 28 2007\n",
      "\n",
      "\n",
      "Iteration: 190000\n",
      "\n",
      "Satursday february 21 1974\n",
      "Tuesday september 17 1988\n",
      "Saturday april 14 1988\n",
      "Ary 3 1986\n",
      "Maer 22 1984\n",
      "Tuesday october 12 1993\n",
      "17 1788\n",
      "\n",
      "\n",
      "Iteration: 192000\n",
      "\n",
      "Sundary 7 1988\n",
      "6 1981\n",
      "August 28 1986\n",
      "Jun 2217\n",
      "Maury 11 1982\n",
      "Saturday september 19 2016\n",
      "1209\n",
      "\n",
      "\n",
      "Iteration: 194000\n",
      "\n",
      "9 89 1970\n",
      "September 19 1973\n",
      "September 7 1978\n",
      "September 10 1980\n",
      "Auesday august 5 1970\n",
      "Friday october 9 1973\n",
      "November 20 1992\n",
      "\n",
      "\n",
      "Iteration: 196000\n",
      "\n",
      " 1975\n",
      "September 29 1985\n",
      "Oceober 7 2003\n",
      "Supt 18 1985\n",
      "September 8 1995\n",
      "97 95\n",
      "Aueday july 23 2018\n",
      "\n",
      "\n",
      "Iteration: 198000\n",
      "\n",
      "October 10 1999\n",
      "Augu 17 1981\n",
      "Oce 21 2006\n",
      "Arcember 6 1990\n",
      "Augu 29 1980\n",
      "September 4 2008\n",
      "March 27 1980\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = model(ix_to_char, char_to_ix, num_iterations=200000, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "1dYg0",
   "launcher_item_id": "MLhxP"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
